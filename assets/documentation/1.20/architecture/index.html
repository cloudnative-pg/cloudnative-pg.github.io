<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="author" content="The CloudNativePG Contributors" />
      <link rel="shortcut icon" href="../img/favicon.ico" />
    <title>Architecture - CloudNativePG</title>
    <link rel="stylesheet" href="../css/theme.css" />
    <link rel="stylesheet" href="../css/theme_extra.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/styles/github.min.css" />
        <link href="../css/override.css" rel="stylesheet" />
    
      <script>
        // Current page data
        var mkdocs_page_name = "Architecture";
        var mkdocs_page_input_path = "architecture.md";
        var mkdocs_page_url = null;
      </script>
    
    <script src="../js/jquery-3.6.0.min.js" defer></script>
    <!--[if lt IE 9]>
      <script src="../js/html5shiv.min.js"></script>
    <![endif]-->
      <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.5.0/highlight.min.js"></script>
      <script>hljs.initHighlightingOnLoad();</script> 
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
    <div class="wy-side-scroll">
      <div class="wy-side-nav-search">
          <a href=".." class="icon icon-home"> CloudNativePG
        </a><div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
      <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="..">CloudNativePG</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../before_you_start/">Before You Start</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../use_cases/">Use cases</a>
                </li>
              </ul>
              <ul class="current">
                <li class="toctree-l1 current"><a class="reference internal current" href="./">Architecture</a>
    <ul class="current">
    <li class="toctree-l2"><a class="reference internal" href="#synchronizing-the-state">Synchronizing the state</a>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#kubernetes-architecture">Kubernetes architecture</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#multi-availability-zone-kubernetes-clusters">Multi-availability zone Kubernetes clusters</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#single-availability-zone-kubernetes-clusters">Single availability zone Kubernetes clusters</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#postgresql-architecture">PostgreSQL architecture</a>
        <ul>
    <li class="toctree-l3"><a class="reference internal" href="#read-write-workloads">Read-write workloads</a>
    </li>
    <li class="toctree-l3"><a class="reference internal" href="#read-only-workloads">Read-only workloads</a>
    </li>
        </ul>
    </li>
    <li class="toctree-l2"><a class="reference internal" href="#deployments-across-kubernetes-clusters">Deployments across Kubernetes clusters</a>
    </li>
    </ul>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../installation_upgrade/">Installation and upgrades</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../quickstart/">Quickstart</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../bootstrap/">Bootstrap</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../database_import/">Importing Postgres databases</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../security/">Security</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../instance_manager/">Postgres instance manager</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../scheduling/">Scheduling</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../resource_management/">Resource management</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../failure_modes/">Failure Modes</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../rolling_update/">Rolling Updates</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../replication/">Replication</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../backup/">Backup</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../recovery/">Recovery</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../postgresql_conf/">PostgreSQL Configuration</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../declarative_role_management/">Database Role Management</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../operator_conf/">Operator configuration</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../cluster_conf/">Instance pod configuration</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../storage/">Storage</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../labels_annotations/">Labels and annotations</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../monitoring/">Monitoring</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../logging/">Logging</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../certificates/">Certificates</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../ssl_connections/">Client TLS/SSL connections</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../applications/">Connecting from an application</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../connection_pooling/">Connection pooling</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../replica_cluster/">Replica clusters</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../kubernetes_upgrade/">Kubernetes Upgrade</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../expose_pg_services/">Exposing Postgres Services</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../kubectl-plugin/">CloudNativePG Plugin</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../failover/">Automated failover</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../troubleshooting/">Troubleshooting</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../fencing/">Fencing</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../declarative_hibernation/">Declarative hibernation</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../postgis/">PostGIS</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../e2e/">End-to-End Tests</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../container_images/">Container Image Requirements</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../operator_capability_levels/">Operator capability levels</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../controller/">Custom Pod Controller</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../samples/">Examples</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../networking/">Networking</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../benchmarking/">Benchmarking</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../commercial_support/">Commercial support</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../faq/">Frequently Asked Questions (FAQ)</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../cloudnative-pg.v1/">API Reference</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../supported_releases/">Supported releases</a>
                </li>
              </ul>
              <ul>
                <li class="toctree-l1"><a class="reference internal" href="../release_notes/">Release notes</a>
                </li>
              </ul>
              <p class="caption"><span class="caption-text">Appendixes</span></p>
              <ul>
                  <li class="toctree-l1"><a class="reference internal" href="../appendixes/object_stores/">Appendix A - Common object stores for backups</a>
                  </li>
              </ul>
      </div>
    </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
      <nav class="wy-nav-top" role="navigation" aria-label="Mobile navigation menu">
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="..">CloudNativePG</a>
        
      </nav>
      <div class="wy-nav-content">
        <div class="rst-content"><div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href=".." class="icon icon-home" alt="Docs"></a> &raquo;</li>
      <li>Architecture</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
            <div class="section" itemprop="articleBody">
              
                <h1 id="architecture">Architecture</h1>
<p>This section covers the main architectural aspects you need to consider
when deploying PostgreSQL in Kubernetes.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>We encourage you to read an article that we've written for the CNCF blog
with title <a href="https://www.cncf.io/blog/2023/09/29/recommended-architectures-for-postgresql-in-kubernetes/">"Recommended Architectures for PostgreSQL in Kubernetes"</a>.</p>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>If you are deploying PostgreSQL in a self-managed Kubernetes environment,
please make sure you read the <a href="#kubernetes-architecture">"Kubernetes architecture"</a>
below when you start planning your journey to the Cloud Native world.</p>
</div>
<h2 id="synchronizing-the-state">Synchronizing the state</h2>
<p>PostgreSQL is a database management system and, as such, it needs to be treated
as a <strong>stateful workload</strong> in Kubernetes. While stateless applications
mainly use traffic redirection to achieve High Availability (HA) and
Disaster Recovery (DR), in the case of a database, state must be replicated in
multiple locations, preferably in a continuous and instantaneous way, by
adopting either of the following two strategies:</p>
<ul>
<li><em>storage-level replication</em>, normally persistent volumes</li>
<li><em>application-level replication</em>, in this specific case PostgreSQL</li>
</ul>
<p>CloudNativePG relies on application-level replication, for a simple reason: the
PostgreSQL database management system comes with robust and reliable
built-in <strong>physical replication</strong> capabilities based on <strong>Write Ahead Log (WAL)
shipping</strong>, which have been used in production by millions of users all over
the world for over a decade.</p>
<p>PostgreSQL supports both asynchronous and synchronous streaming replication
over the network, as well as asynchronous file-based log shipping (normally
used as a fallback option, for example, to store WAL files in an object store).
Replicas are usually called <em>standby servers</em> and can also be used for
read-only workloads, thanks to the <em>Hot Standby</em> feature.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p><strong>We recommend against storage-level replication with PostgreSQL</strong>, although
CloudNativePG allows you to adopt that strategy. For more information, please refer
to the talk given by Chris Milsted and Gabriele Bartolini at KubeCon NA 2022 entitled
<a href="https://www.youtube.com/watch?v=99uSJXkKpeI&amp;ab_channel=CNCF%5BCloudNativeComputingFoundation%5D">"Data On Kubernetes, Deploying And Running PostgreSQL And Patterns For Databases In a Kubernetes Cluster"</a>
where this topic was covered in detail.</p>
</div>
<h2 id="kubernetes-architecture">Kubernetes architecture</h2>
<p>Kubernetes natively provides the possibility to span separate physical
locations - also known as data centers, failure zones, or more frequently
<strong>availability zones</strong> - connected to each other via redundant, low-latency,
private network connectivity.</p>
<p>Being a distributed system, the recommended minimum number of availability
zones for a Kubernetes cluster is three (3), in order to make the control
plane resilient to the failure of a single zone.
For details, please refer to
<a href="https://kubernetes.io/docs/setup/best-practices/multiple-zones/">"Running in multiple zones"</a>.
This means that <strong>each data center is active at any time</strong> and can run workloads
simultaneously.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Most of the public Cloud Providers' managed Kubernetes services already
provide 3 or more availability zones in each region.</p>
</div>
<h3 id="multi-availability-zone-kubernetes-clusters">Multi-availability zone Kubernetes clusters</h3>
<p>The multi-availability zone Kubernetes architecture with three (3) or more
zones is the one that we recommend for PostgreSQL usage.
This scenario is typical of Kubernetes services managed by Cloud Providers.</p>
<p><img alt="Kubernetes cluster spanning over 3 independent data centers" src="../images/k8s-architecture-3-az.png" /></p>
<p>Such an architecture enables the CloudNativePG operator to control the full
lifecycle of a <code>Cluster</code> resource across the zones within a single Kubernetes
cluster, by treating all the availability zones as active: this includes, among
other operations,
<a href="../scheduling/">scheduling</a> the workloads in a declarative manner (based on
affinity rules, tolerations and node selectors), automated failover,
self-healing, and updates. All will work seamlessly across the zones in a single
Kubernetes cluster.</p>
<p>Please refer to the <a href="#postgresql-architecture">"PostgreSQL architecture"</a>
section below for details on how you can design your PostgreSQL clusters within
the same Kubernetes cluster through shared-nothing deployments at the storage,
worker node, and availability zone levels.</p>
<p>Moreover, you can take advantage of additional <a href="#deployments-across-kubernetes-clusters">Kubernetes clusters</a>,
by using them to host "passive" PostgreSQL replica clusters. This should be
used primarily for DR, read-only operations, or cross-region availability,
even though failovers and promotions in this case must be done manually.</p>
<p><img alt="Example of a multiple Kubernetes cluster architecture distributed over 3 regions each with 3 independent data centers" src="../images/k8s-architecture-multi.png" /></p>
<h3 id="single-availability-zone-kubernetes-clusters">Single availability zone Kubernetes clusters</h3>
<p>If your Kubernetes cluster has only one availability zone, CloudNativePG still
provides you with a lot of features to improve HA and DR outcomes for your
PostgreSQL databases, pushing the single point of failure (SPoF) to the level
of the zone as much as possible - i.e. the zone must have an outage before your
CloudNativePG clusters suffer a failure.</p>
<p>This scenario is typical of self-managed on-premise Kubernetes clusters, where
only one data center is available.</p>
<p>Single availability zone Kubernetes is unfortunately the only viable option
where just <strong>two (2) data centers</strong> are available within reach of a low latency
connection (normally in the same metropolitan area): having only two zones
precludes users from creating a multi-availability zone Kubernetes cluster
(as the minimum number of
3 zones is not reached) and forces them to create two different Kubernetes
clusters in an active/passive configuration, where the second cluster is used
primarily for Disaster Recovery.</p>
<p><img alt="Example of a Kubernetes architecture with only 2 data centers" src="../images/k8s-architecture-2-az.png" /></p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>If you are at en early stage of your Kubernetes journey, please share this
document with your infrastructure team. The two data centers setup might
be simply the result of a "lift-and-shift" transition to Kubernetes
from a traditional bare-metal or VM based infrastructure, and the benefits
that Kubernetes offers in a 3+ zone scenario might not have been known,
or addressed at the time the infrastructure architecture was designed.
Ultimately, a third physical location connected to the other two might
represent a valid option to consider for organization, as it reduces the
overall costs of the infrastructure by moving the day-to-day complexity
from the application level down to the physical infrastructure level.</p>
</div>
<p>Please refer to the <a href="#postgresql-architecture">"PostgreSQL architecture"</a>
section below for details on how you can design your PostgreSQL clusters within
your single availability zone Kubernetes cluster through shared-nothing
deployments at the storage and worker node levels only. For HA, in such a
scenario it becomes even more important that the PostgreSQL instances be
located on different worker nodes and do not share the same storage.</p>
<p>For DR, you can push the SPoF above the single zone, by
using additional
<a href="#deployments-across-kubernetes-clusters">Kubernetes clusters</a> to
host "passive" PostgreSQL replica clusters. As with other Kubernetes workloads in
this scenario, promotion of a Kubernetes cluster as primary must be done
manually. As explained below, no automated failover across Kubernetes clusters
is available for PostgreSQL at the moment with CloudNativePG, as the operator
can only work within a single Kubernetes cluster.</p>
<h2 id="postgresql-architecture">PostgreSQL architecture</h2>
<p>CloudNativePG supports clusters based on asynchronous and synchronous
streaming replication to manage multiple hot standby replicas within the same
Kubernetes cluster, with the following specifications:</p>
<ul>
<li>One primary, with optional multiple hot standby replicas for HA</li>
<li>Available services for applications:<ul>
<li><code>-rw</code>: applications connect only to the primary instance of the cluster</li>
<li><code>-ro</code>: applications connect only to hot standby replicas for read-only-workloads</li>
<li><code>-r</code>: applications connect to any of the instances for read-only workloads</li>
</ul>
</li>
<li>Shared-nothing architecture recommended for better resilience of the PostgreSQL cluster:<ul>
<li>PostgreSQL instances should reside on different Kubernetes worker nodes
  and share only the network - as a result, instances should not share
  the storage and preferably use local volumes attached to the node they
  run on</li>
<li>PostgreSQL instances should reside in different availability zones
  within the same Kubernetes cluster / region</li>
</ul>
</li>
</ul>
<p>The below diagram provides a simplistic view of the recommended shared-nothing
architecture for a PostgreSQL cluster spanning across 3 different availability
zones, running on separate nodes, each with dedicated local storage for
PostgreSQL data.</p>
<p><img alt="Bird-eye view of the recommended shared nothing architecture for PostgreSQL in Kubernetes" src="../images/k8s-pg-architecture.png" /></p>
<p>CloudNativePG automatically takes care of updating the above services if
the topology of the cluster changes. For example, in case of failover, it
automatically updates the <code>-rw</code> service to point to the promoted primary,
making sure that traffic from the applications is seamlessly redirected.</p>
<div class="admonition seealso">
<p class="admonition-title">Replication</p>
<p>Please refer to the <a href="../replication/">"Replication" section</a> for more
information about how CloudNativePG relies on PostgreSQL replication,
including synchronous settings.</p>
</div>
<div class="admonition seealso">
<p class="admonition-title">Connecting from an application</p>
<p>Please refer to the <a href="../applications/">"Connecting from an application" section</a> for
information about how to connect to CloudNativePG from a stateless
application within the same Kubernetes cluster.</p>
</div>
<div class="admonition seealso">
<p class="admonition-title">Connection Pooling</p>
<p>Please refer to the <a href="../connection_pooling/">"Connection Pooling" section</a> for
information about how to take advantage of PgBouncer as a connection pooler,
and create an access layer between your applications and the PostgreSQL clusters.</p>
</div>
<h3 id="read-write-workloads">Read-write workloads</h3>
<p>Applications can decide to connect to the PostgreSQL instance elected as
<em>current primary</em> by the Kubernetes operator, as depicted in the following
diagram:</p>
<p><img alt="Applications writing to the single primary" src="../images/architecture-rw.png" /></p>
<p>Applications can use the <code>-rw</code> suffix service.</p>
<p>In case of temporary or permanent unavailability of the primary, for High
Availability purposes CloudNativePG will trigger a failover, pointing the <code>-rw</code>
service to another instance of the cluster.</p>
<h3 id="read-only-workloads">Read-only workloads</h3>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Applications must be aware of the limitations that
<a href="https://www.postgresql.org/docs/current/hot-standby.html">Hot Standby</a>
presents and familiar with the way PostgreSQL operates when dealing with
these workloads.</p>
</div>
<p>Applications can access hot standby replicas through the <code>-ro</code> service made available
by the operator. This service enables the application to offload read-only queries from the
primary node.</p>
<p>The following diagram shows the architecture:</p>
<p><img alt="Applications reading from hot standby replicas in round robin" src="../images/architecture-read-only.png" /></p>
<p>Applications can also access any PostgreSQL instance through the
<code>-r</code> service.</p>
<h2 id="deployments-across-kubernetes-clusters">Deployments across Kubernetes clusters</h2>
<div class="admonition info">
<p class="admonition-title">Info</p>
<p>CloudNativePG supports deploying PostgreSQL across multiple
Kubernetes clusters through a feature called <strong>Replica Cluster</strong>,
which is described in this section.</p>
</div>
<p>In a distributed PostgreSQL cluster there can only be a single PostgreSQL
instance acting as a primary at all times. This means that applications can
only write inside a single Kubernetes cluster, at any time.</p>
<p>However, for business continuity objectives it is fundamental to:</p>
<ul>
<li>reduce global <strong>recovery point objectives</strong> (RPO) by storing PostgreSQL backup data
  in multiple locations, regions and possibly using different providers
  (Disaster Recovery)</li>
<li>reduce global <strong>recovery time objectives</strong> (RTO) by taking advantage of PostgreSQL
  replication beyond the primary Kubernetes cluster (High Availability)</li>
</ul>
<p>In order to address the above concerns, CloudNativePG introduces the
concept of a <em>PostgreSQL Replica Cluster</em>. Replica clusters are the
CloudNativePG way to enable multi-cluster deployments in private, public,
hybrid, and multi-cloud contexts.</p>
<p>A replica cluster is a separate <code>Cluster</code> resource:</p>
<ol>
<li>having either <code>pg_basebackup</code> or full <code>recovery</code> as the <code>bootstrap</code>
   option from a defined external source cluster</li>
<li>having the <code>replica.enabled</code> option set to <code>true</code></li>
<li>replicating from a defined external cluster identified by <code>replica.source</code>,
   normally located outside the Kubernetes cluster</li>
<li>replaying WAL information received from the recovery object store
   (using PostgreSQL's <code>restore_command</code> parameter), or via streaming
   replication (using PostgreSQL's <code>primary_conninfo</code> parameter), or any of
   the two (in case both the <code>barmanObjectStore</code> and <code>connectionParameters</code>
   are defined in the external cluster)</li>
<li>accepting only read connections, as supported by PostgreSQL's Hot Standby</li>
</ol>
<div class="admonition seealso">
<p class="admonition-title">Seealso</p>
<p>Please refer to the <a href="../bootstrap/">"Bootstrap" section</a> for more information
about cloning a PostgreSQL cluster from another one (defined in the
<code>externalClusters</code> section).</p>
</div>
<p>The diagram below depicts a PostgreSQL cluster spanning over two different
Kubernetes clusters, where the primary cluster is in the first Kubernetes
cluster and the replica cluster is in the second. The second Kubernetes cluster
acts as the company's disaster recovery cluster, ready to be activated in case
of disaster and unavailability of the first one.</p>
<p><img alt="An example of multi-cluster deployment with a primary and a replica cluster" src="../images/multi-cluster.png" /></p>
<p>A replica cluster can have the same architecture of the primary cluster. In
place of the primary instance, a replica cluster has a <strong>designated primary</strong>
instance, which is a standby server with an arbitrary number of cascading
standby servers in streaming replication (symmetric architecture).</p>
<p>The designated primary can be promoted at any time, making the replica cluster
a primary cluster capable of accepting write connections.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>CloudNativePG does not perform any cross-cluster switchover
or failover at the moment. Such operation must be performed manually
or delegated to a multi-cluster/federated cluster aware authority.
Each PostgreSQL cluster is independent from any other.</p>
</div>
<p>The designated primary in the above example is fed via WAL streaming
(<code>primary_conninfo</code>), with fallback option for file-based WAL shipping through
the <code>restore_command</code> and <code>barman-cloud-wal-restore</code>.</p>
<p>CloudNativePG allows you to define multiple replica clusters.
You can also define replica clusters with a lower number of replicas, and then
increase this number when the cluster is promoted to primary.</p>
<div class="admonition seealso">
<p class="admonition-title">Replica clusters</p>
<p>Please refer to the <a href="../replica_cluster/">"Replica Clusters" section</a> for more
information about physical replica clusters work and how you can configure
read-only clusters in different Kubernetes cluster to improve your global
disaster recovery and HA strategy.</p>
</div>
              
            </div>
          </div><footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="Footer Navigation">
        <a href="../use_cases/" class="btn btn-neutral float-left" title="Use cases"><span class="icon icon-circle-arrow-left"></span> Previous</a>
        <a href="../installation_upgrade/" class="btn btn-neutral float-right" title="Installation and upgrades">Next <span class="icon icon-circle-arrow-right"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
  </div>

  Built with <a href="https://www.mkdocs.org/">MkDocs</a> using a <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
          
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" aria-label="Versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    
    
      <span><a href="../use_cases/" style="color: #fcfcfc">&laquo; Previous</a></span>
    
    
      <span><a href="../installation_upgrade/" style="color: #fcfcfc">Next &raquo;</a></span>
    
  </span>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme_extra.js" defer></script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/main.js" defer></script>
    <script defer>
        window.onload = function () {
            SphinxRtdTheme.Navigation.enable(true);
        };
    </script>

</body>
</html>
